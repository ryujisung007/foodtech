import google.generativeai as genai
import streamlit as st

def init_gemini():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì‹  Gemini ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ ì—°ê²°"""
    try:
        if "GEMINI_API_KEY" not in st.secrets:
            st.error("Secretsì— 'GEMINI_API_KEY'ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        target_models = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-pro']
        selected = next((m for m in target_models if m in available_models), 
                        available_models[0] if available_models else None)
        
        return genai.GenerativeModel(selected) if selected else None
    except Exception as e:
        return None

def get_product_ideation(company_name, tech_info, product_info):
    """ì‹í’ˆê³µí•™ ë°•ì‚¬ê¸‰ R&D ì œì•ˆì„œ ìƒì„±"""
    model = init_gemini()
    if not model: return "AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"""
    ë‹¹ì‹ ì€ ì‹í’ˆê³µí•™ ë°•ì‚¬ì´ì ì‹í’ˆê¸°ìˆ ì‚¬ì…ë‹ˆë‹¤.
    [{company_name}]ì˜ ê¸°ìˆ ({tech_info})ê³¼ ì†Œì¬({product_info})ë¥¼ ë¶„ì„í•˜ì—¬ 
    ì•„ì´ìŠ¤í¬ë¦¼, ì´ˆì½œë¦¿, ì´ˆì½œë¦¿ ì½”íŒ…, ë² ì´ì»¤ë¦¬ 4ê°œ ë¶„ì•¼ì˜ í˜ì‹  ì œí’ˆì„ ì œì•ˆí•˜ì„¸ìš”.
    - ì „ë¬¸ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ğŸ’¡ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"

def get_chatbot_response(messages, context_df):
    """RAG ê¸°ë°˜ ë°ì´í„° ì°¸ì¡°í˜• ì±—ë´‡"""
    model = init_gemini()
    if not model or not messages: return "ì±—ë´‡ ì‘ë‹µ ë¶ˆê°€ëŠ¥"
    
    context = context_df[['ê¸°ì—…ì´ë¦„', 'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ëŒ€í‘œê¸°ìˆ ', 'ëŒ€í‘œì œí’ˆ']].to_string(index=False)
    system_instr = f"ë‹¹ì‹ ì€ ì‹í’ˆ R&D ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:\n{context}"
    
    try:
        full_prompt = f"{system_instr}\n\nì‚¬ìš©ì ì§ˆë¬¸: {messages[-1]['content']}"
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"ì±—ë´‡ ì˜¤ë¥˜: {str(e)}"
