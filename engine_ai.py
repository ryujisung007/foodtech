import google.generativeai as genai
import streamlit as st

def init_gemini():
    """ê°€ìš©í•œ ìµœì‹  Gemini ëª¨ë¸ì„ ìë™ìœ¼ë¡œ íƒìƒ‰í•˜ì—¬ ì—°ê²°"""
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=api_key)
        
        # ê°€ìš© ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ í•„í„°ë§
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # ìš°ì„ ìˆœìœ„: 1.5-flash -> 1.5-pro -> gemini-pro
        target_models = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-pro']
        selected = next((m for m in target_models if m in available_models), 
                        available_models[0] if available_models else None)
        
        return genai.GenerativeModel(selected) if selected else None
    except Exception as e:
        st.error(f"Gemini ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

def get_product_ideation(company_name, tech_info, product_info):
    """ì‹í’ˆê³µí•™ ë°•ì‚¬ê¸‰ R&D ì œì•ˆì„œ ìƒì„±"""
    model = init_gemini()
    if not model: return "AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    prompt = f"""
    ë‹¹ì‹ ì€ ì‹í’ˆê³µí•™ ë°•ì‚¬ ë° ì‹í’ˆê¸°ìˆ ì‚¬ì…ë‹ˆë‹¤.
    [{company_name}]ì˜ ê¸°ìˆ ({tech_info})ê³¼ ì†Œì¬({product_info})ë¥¼ ë¶„ì„í•˜ì—¬ 
    ì•„ì´ìŠ¤í¬ë¦¼, ì´ˆì½œë¦¿, ì´ˆì½œë¦¿ ì½”íŒ…, ë² ì´ì»¤ë¦¬ 4ê°œ ë¶„ì•¼ì˜ ì‹ ì œí’ˆì„ ì œì•ˆí•˜ì„¸ìš”.
    - íŠ¹íˆ 'ì‹ë¬¼ì„± ê³„ë€(ALOK)'ê³¼ ê°™ì€ ë©”íƒ€í…ìŠ¤ì³ ê¸°ìˆ ì˜ ê²”í™”(Gelation) ë° ì‘ê³  íŠ¹ì§•ì„ ê¸°ìˆ í•˜ì‹­ì‹œì˜¤.
    - ê¸°ìˆ ì€ ì ìš©ë°©ì•ˆ ì¤‘ì‹¬ìœ¼ë¡œ, ì†Œì¬ëŠ” ì‹ ì†Œì¬ ìœµí•© ê¸°ìˆ  ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ğŸ’¡ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"

def get_chatbot_response(messages, context_df):
    """RAG ê¸°ë°˜ ë°ì´í„° ì°¸ì¡°í˜• ì±—ë´‡"""
    model = init_gemini()
    if not model or not messages: return "ì±—ë´‡ ì‘ë‹µ ë¶ˆê°€ëŠ¥"
    
    context = context_df[['ê¸°ì—…ì´ë¦„', 'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ëŒ€í‘œê¸°ìˆ ', 'ëŒ€í‘œì œí’ˆ']].to_string(index=False)
    system_instr = f"ë‹¹ì‹ ì€ ì‹í’ˆ R&D ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:\n{context}"
    
    try:
        full_prompt = f"{system_instr}\n\nì‚¬ìš©ì ì§ˆë¬¸: {messages[-1]['content']}"
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"ì±—ë´‡ ì˜¤ë¥˜: {str(e)}"
