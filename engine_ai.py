import google.generativeai as genai
import streamlit as st

def init_gemini():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì‹  Gemini ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì°¾ì•„ ì—°ê²°í•©ë‹ˆë‹¤."""
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=api_key)
        
        # 1. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ
        available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # 2. ì„ í˜¸ ìˆœìœ„ë³„ ëª¨ë¸ ë§¤ì¹­ (Flash -> Pro -> ìµœì‹ ìˆœ)
        target_models = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'models/gemini-pro']
        
        selected_model = None
        for target in target_models:
            if target in available_models:
                selected_model = target
                break
        
        # 3. ë§¤ì¹­ë˜ëŠ” ëª¨ë¸ì´ ì—†ì„ ê²½ìš° ì²« ë²ˆì§¸ ê°€ìš© ëª¨ë¸ ì„ íƒ
        if not selected_model and available_models:
            selected_model = available_models[0]
            
        if selected_model:
            return genai.GenerativeModel(selected_model)
        else:
            st.error("ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
            
    except Exception as e:
        st.error(f"Gemini API ì„¤ì • ì‹¤íŒ¨: {e}")
        return None

def get_product_ideation(company_name, tech_info, product_info):
    """Gemini ê¸°ë°˜ ì „ë¬¸ R&D ì œì•ˆ ìƒì„±"""
    model = init_gemini()
    if not model: return "API ì„¤ì • ë° ëª¨ë¸ ê°€ìš©ì„±ì„ í™•ì¸í•´ ì£¼ì„¸ìš”."

    prompt = f"""
    ë‹¹ì‹ ì€ ì‹í’ˆê³µí•™ ë°•ì‚¬ì´ì ì‹í’ˆê¸°ìˆ ì‚¬ì…ë‹ˆë‹¤.
    [{company_name}]ì˜ ê¸°ìˆ ({tech_info})ê³¼ ì†Œì¬({product_info})ë¥¼ ë¶„ì„í•˜ì—¬ 
    ì•„ì´ìŠ¤í¬ë¦¼, ì´ˆì½œë¦¿, ì´ˆì½œë¦¿ ì½”íŒ…, ë² ì´ì»¤ë¦¬ 4ê°œ ë¶„ì•¼ì˜ í˜ì‹  ì œí’ˆì„ ì œì•ˆí•˜ì„¸ìš”.
    - íŠ¹íˆ 'ì‹ë¬¼ì„± ê³„ë€(ALOK)' ë“± ë©”íƒ€í…ìŠ¤ì³ ê¸°ìˆ ì˜ ë¬¼ì„±í•™ì  íŠ¹ì§•(ì‘ê³ , ìœ í™”, ê²”í™”)ì„ ê°•ì¡°í•˜ì‹­ì‹œì˜¤.
    - ê¸°ìˆ ì€ ì œí’ˆ ì ìš©ë°©ì•ˆ ì¤‘ì‹¬ìœ¼ë¡œ, ì†Œì¬ëŠ” ì‹ ì†Œì¬ ìœµí•© ê¸°ìˆ  ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ğŸ’¡ ëª¨ë¸ í˜¸ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"

def get_chatbot_response(messages, context_df):
    """ë°ì´í„° ì°¸ì¡°í˜• R&D ì±—ë´‡ (RAG)"""
    model = init_gemini()
    if not model: return "ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨"
    
    context = context_df[['ê¸°ì—…ì´ë¦„', 'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ëŒ€í‘œê¸°ìˆ ', 'ëŒ€í‘œì œí’ˆ']].to_string(index=False)
    system_instruction = f"ë‹¹ì‹ ì€ ì‹í’ˆ R&D ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:\n{context}"
    
    try:
        full_prompt = f"{system_instruction}\n\nì‚¬ìš©ì ì§ˆë¬¸: {messages[-1]['content']}"
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"ì±—ë´‡ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"import google.generativeai as genai
import streamlit as st

def init_gemini():
    """Gemini API ì´ˆê¸°í™” ë° ëª¨ë¸ ì—°ê²° (404 ì˜¤ë¥˜ ë°©ì§€ ê°•í™”)"""
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        genai.configure(api_key=api_key)
        
        # [í•´ê²°ì±…] ëª¨ë¸ëª…ì„ 'gemini-1.5-flash'ë¡œ ë‹¨ìˆœí™”í•˜ì—¬ í˜¸ì¶œí•©ë‹ˆë‹¤.
        # ë§Œì•½ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë¬¸ì œë¡œ 404ê°€ ë°œìƒí•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ 
        # ê°€ì¥ í˜¸í™˜ì„±ì´ ë†’ì€ ëª¨ë¸ëª…ì„ í• ë‹¹í•©ë‹ˆë‹¤.
        model_name = 'gemini-1.5-flash' 
        return genai.GenerativeModel(model_name)
    except Exception as e:
        st.error(f"Gemini API ì„¤ì • ì‹¤íŒ¨: {e}")
        return None

def get_product_ideation(company_name, tech_info, product_info):
    """Gemini ê¸°ë°˜ 4ëŒ€ ì¹´í…Œê³ ë¦¬ R&D ì œì•ˆ (í…ìŠ¤íŠ¸ ìƒì„±)"""
    model = init_gemini()
    if not model: return "API ì„¤ì • í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤."

    prompt = f"""
    ë‹¹ì‹ ì€ ì‹í’ˆê³µí•™ ë°•ì‚¬ ë° ì‹í’ˆê¸°ìˆ ì‚¬ì…ë‹ˆë‹¤.
    [{company_name}]ì˜ ê¸°ìˆ ({tech_info})ê³¼ ì†Œì¬({product_info})ë¥¼ ë¶„ì„í•˜ì—¬ 
    ì•„ì´ìŠ¤í¬ë¦¼, ì´ˆì½œë¦¿, ì´ˆì½œë¦¿ ì½”íŒ…, ë² ì´ì»¤ë¦¬ 4ê°œ ë¶„ì•¼ì˜ í˜ì‹  ì œí’ˆì„ ì œì•ˆí•˜ì„¸ìš”.
    - ê¸°ìˆ ì€ ì œí’ˆ ì ìš©ë°©ì•ˆ ì¤‘ì‹¬ìœ¼ë¡œ, ì†Œì¬ëŠ” ì‹ ì†Œì¬ ìœµí•© ê¸°ìˆ  ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    - 'ì‹ë¬¼ì„± ê³„ë€(ALOK)' ë“± ë©”íƒ€í…ìŠ¤ì³ ê¸°ìˆ ì˜ ë¬¼ì„±í•™ì  íŠ¹ì§•ì„ ê°•ì¡°í•˜ì‹­ì‹œì˜¤.
    """
    try:
        # ëª¨ë¸ í˜¸ì¶œ ì‹œë„
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        # 404 ì—ëŸ¬ ë°œìƒ ì‹œ ì‚¬ìš©ìì—ê²Œ ëª…í™•í•œ ê°€ì´ë“œ ì œê³µ
        return f"ğŸ’¡ [ì—°ê²° ì •ë³´] ëª¨ë¸ëª…ì„ 'gemini-1.5-flash'ë¡œ í™•ì¸í•´ ì£¼ì„¸ìš”. (ì—ëŸ¬: {str(e)})"

def get_chatbot_response(messages, context_df):
    """Gemini ê¸°ë°˜ ë°ì´í„° ì°¸ì¡° ì±—ë´‡ (RAG)"""
    model = init_gemini()
    if not model: return "ì±—ë´‡ ì´ˆê¸°í™” ì‹¤íŒ¨"
    
    # ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = context_df[['ê¸°ì—…ì´ë¦„', 'ì¤‘ë¶„ë¥˜', 'ì†Œë¶„ë¥˜', 'ëŒ€í‘œê¸°ìˆ ', 'ëŒ€í‘œì œí’ˆ']].to_string(index=False)
    system_instruction = f"ë‹¹ì‹ ì€ ì‹í’ˆ R&D ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”:\n{context}"
    
    try:
        # ì‚¬ìš©ì ì§ˆë¬¸ì— ì»¨í…ìŠ¤íŠ¸ ê²°í•©
        full_prompt = f"{system_instruction}\n\nì‚¬ìš©ì ì§ˆë¬¸: {messages[-1]['content']}"
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"ì±—ë´‡ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
